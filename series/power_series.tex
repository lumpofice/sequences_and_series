\section{Power Series}

\begin{definition}
Given a sequence $\{c_{n}\}_{n=0}^{\infty}$ of real numbers and
\begin{align*}
    f(x) = \sum_{n=0}^{\infty} c_{n} (x - a)^{n}
\end{align*}
where $a$ is a real number, we say $f$ is a power series centered at $a$.
\end{definition}

\begin{note}
The reader may replace the word ``radius" in this section with the word ``interval", but in general, ``radius" means ``ball", whether that ``ball" be a one-dimensional interval, a two-dimensional disk, a three-dimensional sphere, etc. Thus, for any natural number $n$, one may refer to a ``radius" in $n$-dimensional space as a ``ball".
\end{note}

Function $f$ will have a radius of convergence for some $x$, since
\begin{align*}
    f(x) &= c_{0} (x - a)^{0} + c_{1} (x - a)^{1} + c_{2} (x - a)^{2} + \cdots\\[2ex]
    &= c_{0} + c_{1} (x - a) + c_{2} (x - a)^{2} + \cdots
\end{align*}
which becomes the finite number, $c_{0}$, as soon as $x = a$. Our job is to find this radius of convergence and the object to which the series converges. 

\begin{note}
A series converges if its sequence of partial sums converges.
\end{note}

We begin with finding the radius of convergence, for which there are three possible outcomes
\begin{itemize}
    \item $f$ converges for $x \in \{a\}$
    \item $f$ converges for $x \in (-\infty, \infty)$
    \item $f$ converges for $x \in (-R, R)$, where $R$ is finite. 
\end{itemize}

\begin{example}
Take the function
\begin{align*}
    f(x) = \sum_{n=0}^{\infty} x^{n} = 1 + x + x^{2} + x^{3} + \cdots = \dfrac{1}{1-x}
\end{align*}
which we discovered is convergent when $x \in (-1, 1)$. Function $f$ is the power series centered about $a=0$. Using the ratio test
\begin{align*}
    \Big\lvert \dfrac{x^{n+1}}{x^{n}} \Big\rvert = \lvert x \rvert \hspace{20pt} \text{and} \hspace{20pt} \lim_{n \longrightarrow \infty} \lvert x \rvert = \lvert x \rvert < 1 \hspace{20pt} \text{if and only if} \hspace{20pt} -1 < x < 1
\end{align*}
\end{example}

\begin{theorem}
Let $n$ be a natural number on $[\alpha, \beta]$, let $f$ be a function such that $f$ and all of its derivatives are continuous on $[\alpha, \beta]$ and $f^{(n+1)}$ exists on $(\alpha, \beta)$. If $a$ is in $[\alpha, \beta]$, then for any $x$ in $[\alpha, \beta]$, there exists a point $c$ between $x$ and $a$ such that
\begin{align*}
    f(x) = f(a) + f^{(1)}(a)(x-a) + \dfrac{f^{(2)}(a)}{2!}(x-a)^{2} + \cdots + \dfrac{f^{(n)}(a)}{n!}(x-a)^{n} + \dfrac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}
\end{align*}
where
\begin{align*}
    f(a) + f^{(1)}(a)(x-a) + \dfrac{f^{(2)}(a)}{2!}(x-a)^{2} + \cdots + \dfrac{f^{(n)}(a)}{n!}(x-a)^{n}
\end{align*}
is the $n^{th}$ term in the sequence
\begin{align*}
    \Big\{\sum_{i=0}^{k} \dfrac{f^{(i)}(x_{0})}{i!}(x-a)^{i}\Big\}_{k=0}^{\infty}
\end{align*}
which we may abbreviate as $T_{n}(x)$, and 
\begin{align*}
    \dfrac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}
\end{align*}
is referred to as the remainder, which we may abbreviate as $R_{n}(x)$.
\end{theorem}


We refer to $f$ as the Taylor Series and can write it as
\begin{align*}
    f(x) = \sum_{n=0}^{\infty} \dfrac{f^{(n)}(a)}{n!}(x-a)^{n} \hspace{20pt} \text{for} \hspace{4pt} x \in (-R + a, R + a)
\end{align*}
if and only if
\begin{align*}
    \lim_{n \longrightarrow \infty} R_{n}(x) = 0 \hspace{20pt} \text{for each} \hspace{4pt} x \in (-R + a, R + a)
\end{align*}

\begin{note}
Each $T_{n}(x)$ is a partial sum and is referred to as the $n^{th}$ Taylor polynomial.
\end{note}

\begin{note}
From the definition of a power series to the Taylor polynomial, we see
\begin{align*}
    c_{n} = \dfrac{f^{(n)}(a)}{n!}
\end{align*}
\end{note}
